episode,reward,accuracy,steps,buffer_size,epsilon,loss
0,-105964.0,0.16534746760895172,84900,84900,0.8928140475318564,0.4474610371152625
1,-82546.0,0.1708717826002423,66863,100000,0.8871975377251805,0.7190232889624046
2,-29402.0,0.1739076102803349,24007,100000,0.8851900882025361,0.6328508051799487
3,-37636.5,0.1745040650406504,30750,100000,0.8826258232592239,0.5015964391074045
4,-20990.0,0.1823917407513622,17435,100000,0.8811754049059851,0.4691216761133614
5,-73917.5,0.17801305341378007,60827,100000,0.87613495957003,0.3883296490204426
6,-46031.5,0.18717948717948718,38610,100000,0.8729514023032917,0.4312291230308796
7,-11569.5,0.17939534393763826,9493,100000,0.8721705452295356,0.42993530717241896
8,-13413.0,0.1830884987459692,11164,100000,0.8712531861979319,0.416096262336151
